"""
Main Nurture Layer engine - orchestrates the full interaction loop.
"""
import re
from datetime import datetime
from typing import Dict, Any, Tuple, Optional, Callable, List

from system_config import NurtureConfig, DEFAULT_NURTURE_CONFIG as DEFAULT_CONFIG
from .state import NurtureState, EvaluationResult, InteractionMetadata, initialize_nurture_state
from .significance import compute_significance, should_evaluate, get_dynamic_threshold
from .evaluation import create_evaluation_prompt, parse_evaluation, extract_basic_features
from .updates import (
    update_N_env, update_env_json, update_N_stance,
    update_stability, compute_plasticity, check_for_shock,
    process_shock, update_stable_count
)
from .context import (
    assemble_context, create_response_prompt_with_significance,
    DEFAULT_SYSTEM_PROMPT
)


class NurtureEngine:
    """
    Main engine for processing interactions through the Nurture Layer.
    """
    
    def __init__(
        self,
        config: NurtureConfig = DEFAULT_CONFIG,
        model_fn: Optional[Callable[[str], str]] = None,
        system_prompt: str = DEFAULT_SYSTEM_PROMPT
    ):
        """
        Initialize the Nurture Engine.
        
        Args:
            config: Configuration parameters
            model_fn: Function to call the LLM (input: prompt, output: response)
            system_prompt: Base system prompt
        """
        self.config = config
        self.model_fn = model_fn
        self.system_prompt = system_prompt
    
    def set_model_fn(self, model_fn: Callable[[str], str]):
        """Set the model function for LLM calls."""
        self.model_fn = model_fn
    
    def create_instance(self, instance_id: Optional[str] = None) -> NurtureState:
        """Create a new nurture state instance."""
        return initialize_nurture_state(
            instance_id=instance_id,
            d_env=self.config.D_ENV,
            d_stance=self.config.D_STANCE
        )
    
    def process_interaction(
        self,
        user_input: str,
        nurture_state: NurtureState,
        conversation_history: List[Dict[str, str]] = None,
        assistant_response: Optional[str] = None,
        extra_context: Optional[str] = None
    ) -> Tuple[str, NurtureState, InteractionMetadata]:
        """
        Process a single interaction through the Nurture Layer.
        Wrapper calling generate_response then update_state.
        """
        # Step 1: Generate response
        response, significance_tag, context = self.generate_response(
            user_input=user_input,
            nurture_state=nurture_state,
            conversation_history=conversation_history,
            assistant_response=assistant_response,
            extra_context=extra_context
        )
        
        # Step 2: Update state
        updated_state, metadata = self.update_state(
            user_input=user_input,
            assistant_response=response,
            significance_tag=significance_tag,
            nurture_state=nurture_state
        )
        
        return response, updated_state, metadata

    def generate_response(
        self,
        user_input: str,
        nurture_state: NurtureState,
        conversation_history: List[Dict[str, str]] = None,
        assistant_response: Optional[str] = None,
        extra_context: Optional[str] = None
    ) -> Tuple[str, str, str]:
        """
        Generate the response and determine significance tag.
        Returns: (response, significance_tag, context_used)
        """
        if conversation_history is None:
            conversation_history = []
        
        # Assemble context
        context = assemble_context(
            system_prompt=self.system_prompt,
            nurture_state=nurture_state,
            conversation_history=conversation_history,
            current_input=user_input,
            include_phase_info=True,
            include_env_summary=True
        )
        
        # Inject experiential context if provided
        if extra_context:
            context = context + f"\n\n[Session Context]\n{extra_context}\n"
        
        # Generate response if not provided
        if assistant_response is None:
            if self.model_fn is None:
                assistant_response = "[Response would be generated by LLM]"
                significance_tag = "medium"
            else:
                full_prompt = context + create_response_prompt_with_significance()
                raw_response = self.model_fn(full_prompt)
                assistant_response, significance_tag = self._extract_significance_tag(raw_response)
        else:
            significance_tag = "medium"
            
        return assistant_response, significance_tag, context

    def update_state(
        self,
        user_input: str,
        assistant_response: str,
        significance_tag: str,
        nurture_state: NurtureState
    ) -> Tuple[NurtureState, InteractionMetadata]:
        """Update nurture state based on the interaction."""
        
        phase_before = nurture_state.phase
        
        # Compute significance
        significance_score, component_scores = compute_significance(
            user_input,
            nurture_state,
            significance_tag,
            self.config
        )
        
        # Check evaluation
        needs_evaluation = should_evaluate(significance_score, nurture_state.plasticity, self.config)
        
        delta_magnitude = 0.0
        shock_detected = False
        
        if needs_evaluation:
            # Run evaluation pass
            evaluation_result = self._run_evaluation(
                user_input, 
                assistant_response, 
                nurture_state
            )
            
            # Update N_env (ungated)
            nurture_state.N_env = update_N_env(
                nurture_state.N_env,
                evaluation_result.environment,
                self.config.ENV_LEARNING_RATE
            )
            nurture_state.env_json = update_env_json(
                nurture_state.env_json,
                evaluation_result.environment,
                self.config.ENV_LEARNING_RATE,
                nurture_state.interaction_count
            )
            
            # Update N_stance (gated)
            nurture_state.N_stance, nurture_state.stance_json, delta_magnitude = update_N_stance(
                nurture_state.N_stance,
                nurture_state.stance_json,
                evaluation_result.stance_updates,
                evaluation_result.alignment_score,
                nurture_state.plasticity,
                self.config
            )
            
            # Update stability
            nurture_state.stability, nurture_state.delta_history = update_stability(
                nurture_state.stability,
                delta_magnitude,
                nurture_state.delta_history,
                self.config
            )
            
            # Check for shock
            shock_boost = check_for_shock(delta_magnitude, nurture_state.plasticity, self.config)
            shock_detected = shock_boost > 0
            
            # Update plasticity
            nurture_state.plasticity = compute_plasticity(nurture_state.stability, self.config)
            if shock_detected:
                nurture_state.plasticity = process_shock(
                    nurture_state.plasticity,
                    shock_boost,
                    self.config
                )
            
            # Update stable count
            nurture_state.stable_count = update_stable_count(
                nurture_state.stable_count,
                delta_magnitude
            )
            
            nurture_state.significant_count += 1
        
        else:
            # Minor N_env update only
            basic_features = extract_basic_features(user_input)
            nurture_state.N_env = update_N_env(
                nurture_state.N_env,
                basic_features,
                self.config.MINOR_ENV_LR
            )
            nurture_state.env_json = update_env_json(
                nurture_state.env_json,
                basic_features,
                self.config.MINOR_ENV_LR,
                nurture_state.interaction_count
            )
        
        # Update counters and timestamps
        nurture_state.interaction_count += 1
        nurture_state.last_updated = datetime.now()
        nurture_state.update_phase()
        
        # Create metadata
        metadata = InteractionMetadata(
            significance_score=significance_score,
            significance_tag=significance_tag,
            was_evaluated=needs_evaluation,
            delta_magnitude=delta_magnitude,
            shock_detected=shock_detected,
            phase_before=phase_before,
            phase_after=nurture_state.phase
        )
        
        return nurture_state, metadata
    
    def _extract_significance_tag(self, response: str) -> Tuple[str, str]:
        """Extract significance tag from model response."""
        # Look for [SIGNIFICANCE: xxx] pattern
        match = re.search(r'\[SIGNIFICANCE:\s*(low|medium|high)\]', response, re.IGNORECASE)
        
        if match:
            tag = match.group(1).lower()
            # Remove the tag from the response
            clean_response = re.sub(r'\n?\[SIGNIFICANCE:\s*(low|medium|high)\]', '', response, flags=re.IGNORECASE)
            return clean_response.strip(), tag
        
        return response, "medium"
    
    def _run_evaluation(
        self,
        user_input: str,
        assistant_response: str,
        nurture_state: NurtureState
    ) -> EvaluationResult:
        """
        Run the internal evaluation pass.
        """
        if self.model_fn is None:
            # Return default evaluation for testing
            return EvaluationResult(
                environment={
                    'formality_level': 'neutral',
                    'technical_level': 'intermediate',
                    'emotional_tone': 'neutral',
                    'pace_preference': 'moderate',
                    'key_traits': []
                },
                alignment_score=0.9,
                stance_updates={},
                tensions=[],
                raw_evaluation="[No LLM available for evaluation]"
            )
        
        # Create evaluation prompt
        eval_prompt = create_evaluation_prompt(
            user_input,
            assistant_response,
            nurture_state.env_json,
            nurture_state.stance_json
        )
        
        # Get evaluation from model
        raw_evaluation = self.model_fn(eval_prompt)
        
        # Parse the evaluation
        return parse_evaluation(raw_evaluation)
    
    def get_state_summary(self, nurture_state: NurtureState) -> Dict[str, Any]:
        """Get a human-readable summary of the nurture state."""
        return {
            'instance_id': nurture_state.instance_id,
            'phase': nurture_state.phase,
            'stability': round(nurture_state.stability, 3),
            'plasticity': round(nurture_state.plasticity, 3),
            'interaction_count': nurture_state.interaction_count,
            'significant_count': nurture_state.significant_count,
            'stance': {k: round(v, 3) for k, v in nurture_state.stance_json.items()},
            'environment': nurture_state.env_json,
            'current_threshold': round(
                get_dynamic_threshold(nurture_state.plasticity, self.config), 3
            )
        }


# Convenience function for simple usage
def create_engine(
    model_fn: Optional[Callable[[str], str]] = None,
    config: Optional[NurtureConfig] = None,
    system_prompt: Optional[str] = None
) -> NurtureEngine:
    """Create a NurtureEngine with specified parameters."""
    return NurtureEngine(
        config=config or DEFAULT_CONFIG,
        model_fn=model_fn,
        system_prompt=system_prompt or DEFAULT_SYSTEM_PROMPT
    )
